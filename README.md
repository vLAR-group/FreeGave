# FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity (CVPR2025)

<h4 align="center">

[![License: GPL-3.0](https://img.shields.io/badge/License-GPL3.0-green)](./LICENSE)

<p>
    <img width="100%" alt="pipeline" src="./assets/teaser.png">
</p>

</h4>

This repository will contain the official implementation of the paper: *FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity*.
FreeGave is a framework that learns 3D geometry, appearance and velocity purely from multi-view videos, achieving SOTA performance in future extrapolation task on four datasets. 

Please feel free to contact us via jinxi.li@connect.polyu.hk or open an issue if you have any questions or suggestions.

## ğŸ“¹ Demo

<p>
    <img width="100%" alt="pipeline" src="./assets/demo.gif">
</p>


## ğŸ“¢ News
- **2025-02-26**: FreeGave is accepted by CVPR2025 ğŸ‰ï¼ 

## ğŸ“‹ TODO
- [ ] Submit the paper onto arXiv.
- [ ] Release pretrained checkpoints. 
- [ ] Release training codes and data. 

## ğŸ˜Š Acknowledgement
This work is adapted from [Deformable-3DGS](https://github.com/ingra14m/Deformable-3D-Gaussians) and [NVFi](https://github.com/vLAR-group/NVFi),
and we would like to thank the authors for their great work.



## ğŸ“š Citation
If you find our work helpful, please consider citing:
```bibtex
@article{li2025freegave,
  title={FreeGave: 3D Physics Learning from Dynamic Videos by Gaussian Velocity}, 
  author={Jinxi Li and Ziyang Song and Siyuan Zhou and Bo Yang},
  year={2025},
  journal={CVPR}
}
```
